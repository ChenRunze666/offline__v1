# seatunnel version 2.3.8
# bigdata env CDH 6.3.2

env {
    parallelism = 2
    job.mode = "BATCH"
}

source{
    Jdbc {
        url = "jdbc:mysql://cdh03:3306/dev_offline_ecommerce_v2?serverTimezone=GMT%2b8&useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&useSSL=false&allowPublicKeyRetrieval=true"
        driver = "com.mysql.cj.jdbc.Driver"
        connection_check_timeout_sec = 100
        user = "root"
        password = "root"
        query = "select * from dev_offline_ecommerce_v2.order"
        # 确保包含分区字段
        column-names: ["*", "ds"]
    }
}

transform {
  Sql {
    query = """
    SELECT
        *,
        DATE_FORMAT(order_time, '%Y%m%d') AS ds  -- 转为yyyyMMdd格式
    FROM source_table
    """
  }
}

sink {
    Hive {
        table_name = "dev_offline_ecommerce_v2.order"
        metastore_uri = "thrift://cdh01:9083"
        hive.hadoop.conf-path = "/etc/hadoop/conf"

        # 动态分区配置
        partition.keys = ["ds"]
        write.mode = "append"

        # 动态分区参数
        hive.partition.write = "dynamic"
        hive.dynamic.partition = "true"
        hive.exec.dynamic.partition.mode = "nonstrict"

        # 核心存储配置
        file.format = "orc"          # orc/parquet/text
        compress.codec = "snappy"    # snappy/zlib/lzo

    }
}
